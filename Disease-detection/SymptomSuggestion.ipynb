{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcDTmIyqctTq"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from statistics import mean\n",
    "from nltk.corpus import wordnet \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import operator\n",
    "from xgboost import XGBClassifier\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUcEIGoij4o8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhrzSJPadBwH"
   },
   "outputs": [],
   "source": [
    "# returns the list of synonyms of the input word from thesaurus.com (https://www.thesaurus.com/) and wordnet (https://www.nltk.org/howto/wordnet.html)\n",
    "def synonyms(term):\n",
    "    synonyms = []\n",
    "    response = requests.get('https://www.thesaurus.com/browse/{}'.format(term))\n",
    "    soup = BeautifulSoup(response.content,  \"html.parser\")\n",
    "    try:\n",
    "        container=soup.find('section', {'class': 'MainContentContainer'}) \n",
    "        row=container.find('div',{'class':'css-191l5o0-ClassicContentCard'})\n",
    "        row = row.find_all('li')\n",
    "        for x in row:\n",
    "            synonyms.append(x.get_text())\n",
    "    except:\n",
    "        None\n",
    "    for syn in wordnet.synsets(term):\n",
    "        synonyms+=syn.lemma_names()\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwigX34ldGPl"
   },
   "outputs": [],
   "source": [
    "# utlities for pre-processing\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZTXyRhNgN_O"
   },
   "source": [
    "Disease Combination dataset contains the combinations for each of the disease present in dataset as practically it is often observed that it is not necessary for a person to have a disease when all the symptoms are faced by the patient or the user.\n",
    "\n",
    "*To tackle this problem, combinations are made with the symptoms for each disease.*\n",
    "\n",
    " **This increases the size of the data exponentially and helps the model to predict the disease with much better accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1LSI08aiDTn"
   },
   "source": [
    "*df_comb -> Dataframe consisting of dataset generated by combining symptoms for each disease.*\n",
    "\n",
    "*df_norm -> Dataframe consisting of dataset which contains a single row for each diseases with all the symptoms for that corresponding disease.*\n",
    "\n",
    "**Dataset contains 261 diseases and their symptoms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fzGWm5NdIkN"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_comb = pd.read_csv(\"/content/drive/My Drive/Python Project data/IR_Project/dis_sym_dataset_comb.csv\") # Disease combination\n",
    "df_norm = pd.read_csv(\"/content/drive/My Drive/Python Project data/IR_Project/dis_sym_dataset_norm.csv\") # Individual Disease\n",
    "\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4fuvOxOhR6v"
   },
   "source": [
    "Using **Logistic Regression (LR) Classifier** as it gives better accuracy compared to other classification models as observed in the comparison of model accuracies in Model_latest.py\n",
    "\n",
    "Cross validation is done on dataset with cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Njmbkf6IdKwt"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X, Y)\n",
    "scores = cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gvck32ifdVZV"
   },
   "outputs": [],
   "source": [
    "X = df_norm.iloc[:, 1:]\n",
    "Y = df_norm.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ppiBHtudX1O"
   },
   "outputs": [],
   "source": [
    "# List of symptoms\n",
    "dataset_symptoms = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNytuZen1Ij3"
   },
   "source": [
    "# Symptoms initially taken from user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6eRjwZhQdbxN",
    "outputId": "0b698f30-810b-42f2-e47b-128564d3d6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter symptoms separated by comma(,):\n",
      "coughing,pyrexia,tire,loss of smell\n"
     ]
    }
   ],
   "source": [
    "# Taking symptoms from user as input \n",
    "user_symptoms = str(input(\"Enter your symptoms separated by comma(,):\\n\")).lower().split(',')\n",
    "# Preprocessing the input symptoms\n",
    "processed_user_symptoms=[]\n",
    "for sym in user_symptoms:\n",
    "    sym=sym.strip()\n",
    "    sym=sym.replace('-',' ')\n",
    "    sym=sym.replace(\"'\",'')\n",
    "    sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "    processed_user_symptoms.append(sym)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SymptomSuggestion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
